# ImgStegGAN

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Version: V1.0.0**

---

<div align="center">

### ğŸŒ Language Selection | è¯­è¨€é€‰æ‹©

**[ä¸­æ–‡](#-ä¸­æ–‡æ–‡æ¡£)** | **[English](#-english-documentation)**

</div>

---

<!-- CHINESE VERSION -->
<a name="ä¸­æ–‡æ–‡æ¡£"></a>
# ä¸­æ–‡æ–‡æ¡£

<div align="right">

**[English Version](#-english-documentation)**

</div>

ä¸€ä¸ªé«˜æ€§èƒ½çš„å›¾åƒéšå†™ç³»ç»Ÿï¼Œç»“åˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ä¸ Qwen è¯­è¨€æ¨¡å‹å¢å¼ºï¼Œå®ç°å®‰å…¨é«˜æ•ˆçš„éšè—æ¶ˆæ¯åµŒå…¥å’Œæå–ã€‚

## åŠŸèƒ½ç‰¹æ€§

- **åŸºäº GAN çš„éšå†™æœ¯**ï¼šåˆ©ç”¨æ·±åº¦å­¦ä¹  GAN æ¶æ„å®ç°é²æ£’çš„æ¶ˆæ¯éšè—
- **Qwen å¢å¼º**ï¼šé›†æˆ Qwen è¯­è¨€æ¨¡å‹ï¼Œå®ç°è¯­ä¹‰ç†è§£å’Œæ”¹è¿›ç¼–ç 
- **é«˜å®¹é‡**ï¼šæ”¯æŒåµŒå…¥å¤§é‡æ¶ˆæ¯ï¼ŒåŒæ—¶ä¿æŒå›¾åƒè´¨é‡
- **æ— æŸæå–**ï¼š100% å‡†ç¡®çš„æ¶ˆæ¯æå–ï¼Œå¸¦çº é”™åŠŸèƒ½
- **ç»´åº¦ä¿æŒ**ï¼šè¾“å‡ºå›¾åƒä¿æŒä¸åŸå§‹å›¾åƒå®Œå…¨ç›¸åŒçš„å°ºå¯¸
- **Web ç•Œé¢**ï¼šç°ä»£åŒ–ã€ä¸“ä¸šçš„ Web UIï¼Œä¾¿äºæ“ä½œ
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒåŒæ—¶å¤„ç†å¤šå¼ å›¾åƒ
- **GPU åŠ é€Ÿ**ï¼šæ”¯æŒ CUDAï¼Œå®ç°æ›´å¿«çš„å¤„ç†é€Ÿåº¦

## é¡¹ç›®ç»“æ„

```
ImgStegGAN/
â”œâ”€â”€ steganogan/                 # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                  # å‘½ä»¤è¡Œæ¥å£
â”‚   â”œâ”€â”€ models.py               # GAN æ¨¡å‹
â”‚   â”œâ”€â”€ encoders.py             # ç¼–ç å™¨æ¶æ„
â”‚   â”œâ”€â”€ decoders.py             # è§£ç å™¨æ¶æ„
â”‚   â”œâ”€â”€ critics.py              # åˆ¤åˆ«å™¨ç½‘ç»œ
â”‚   â”œâ”€â”€ qwen_integration.py     # Qwen æ¨¡å‹é›†æˆ
â”‚   â”œâ”€â”€ trainer.py              # è®­ç»ƒå·¥å…·
â”‚   â”œâ”€â”€ data_loader.py          # æ•°æ®åŠ è½½å·¥å…·
â”‚   â”œâ”€â”€ utils.py                # è¾…åŠ©å‡½æ•°
â”‚   â”œâ”€â”€ compat.py               # PyTorch å…¼å®¹æ€§
â”‚   â””â”€â”€ config.py               # é…ç½®
â”œâ”€â”€ web_interface/              # Web åº”ç”¨
â”‚   â”œâ”€â”€ app.py                  # Flask åº”ç”¨
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/style.css       # æ ·å¼
â”‚   â”‚   â””â”€â”€ js/app.js           # å‰ç«¯é€»è¾‘
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html          # ä¸»æ¨¡æ¿
â”‚   â””â”€â”€ uploads/                # ä¸Šä¼ ç›®å½•
â”œâ”€â”€ output_qwen/                # æ¨¡å‹è¾“å‡º
â”‚   â””â”€â”€ qwen_steganogan.steg    # é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ train.py                    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ setup.py                    # åŒ…è®¾ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–
â””â”€â”€ README.md                   # æ–‡æ¡£
```

## å®‰è£…

### å‰ç½®è¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- PyTorch 2.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- CUDAï¼ˆå¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿï¼‰

### ä»æºç å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/ImgStegGAN.git
cd ImgStegGAN

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
.\venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…åŒ…
pip install -e .
```

### ä¾èµ–é¡¹

```
torch>=2.0.0
torchvision>=0.15.0
Pillow>=9.0.0
numpy>=1.21.0
reedsolo>=1.0.0
tqdm>=4.64.0
flask>=2.0.0
flask-cors>=3.0.0
transformers>=4.30.0
```

## Qwen3 æ¨¡å‹é…ç½®

æœ¬é¡¹ç›®ä½¿ç”¨ Qwen3-0.6B è¿›è¡Œå¢å¼ºéšå†™ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®æ¨¡å‹ã€‚

### æ­¥éª¤ 1ï¼šä¸‹è½½ Qwen3-0.6B æ¨¡å‹

ä»ä»¥ä¸‹å®˜æ–¹æ¥æºä¹‹ä¸€ä¸‹è½½ï¼š

| æ¥æº | URL |
|--------|-----|
| Hugging Face | https://huggingface.co/Qwen/Qwen3-0.6B |
| ModelScope | https://modelscope.cn/models/Qwen/Qwen3-0.6B |

**æ¨èç‰ˆæœ¬**ï¼šQwen3-0.6Bï¼ˆçº¦ 1.2GBï¼‰

### æ­¥éª¤ 2ï¼šåˆ›å»ºæ¨¡å‹ç›®å½•

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º Qwen ç›®å½•
mkdir -p Qwen/Qwen3-0.6B
```

### æ­¥éª¤ 3ï¼šæ”¾ç½®æ¨¡å‹æ–‡ä»¶

ä¸‹è½½å¹¶å°†ä»¥ä¸‹æ–‡ä»¶æ”¾ç½®åˆ° `Qwen/Qwen3-0.6B/`ï¼š

```
Qwen/
â””â”€â”€ Qwen3-0.6B/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ generation_config.json
    â”œâ”€â”€ merges.txt
    â”œâ”€â”€ model.safetensors      # æˆ– pytorch_model.bin
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ vocab.json
```

### æ­¥éª¤ 4ï¼šéªŒè¯é…ç½®

è¿è¡ŒéªŒè¯è„šæœ¬ï¼š

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_path = "./Qwen/Qwen3-0.6B"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)

print("Qwen3 model loaded successfully!")
```

### å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ Hugging Face è‡ªåŠ¨ä¸‹è½½

å¦‚æœæ‚¨æœ‰ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼Œæ¨¡å‹å¯ä»¥åœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ï¼š

```python
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰
import os
os.environ['QWEN_MODEL_NAME'] = 'Qwen/Qwen3-0.6B'

# æˆ–åœ¨ä»£ç ä¸­
from steganogan.qwen_integration import QwenSteganoGAN
model = QwenSteganoGAN(use_local_model=False)  # å°†ä» HuggingFace ä¸‹è½½
```

è¯¦ç»†é…ç½®è¯·å‚è§ [MODEL_SETUP.md](MODEL_SETUP.md)ã€‚

## è®­ç»ƒæ•°æ®é›†

ä»¥ä¸‹æ•°æ®é›†ç”¨äºè®­ç»ƒéšå†™æ¨¡å‹ã€‚

| æ•°æ®é›† | æè¿° | å¤§å° | æ¥æº |
|---------|-------------|------|--------|
| Flickr2K | é«˜è´¨é‡è®­ç»ƒå›¾åƒ | ~2GB | [HuggingFace](https://huggingface.co/datasets/laion/Flickr2K) |
| DIV2K | å¤šæ ·åŒ–é«˜åˆ†è¾¨ç‡å›¾åƒ | ~3.5GB | [Data](https://data.vision.ee.ethz.ch/cvl/DIV2K/) |
| COCO-2017 | ä¸Šä¸‹æ–‡ä¸­çš„å¸¸è§ç‰©ä½“ | ~18GB | [COCO](https://cocodataset.org/) |

### è®­ç»ƒæ•°æ®å‡†å¤‡

1. ä»ä¸Šè¿°æ¥æºä¸‹è½½æ•°æ®é›†
2. å°†å›¾åƒæ”¾ç½®åˆ° `research/data/[æ•°æ®é›†åç§°]/images/`
3. è¿è¡Œè®­ç»ƒï¼š`python train.py --data_root ./research/data`

## ä½¿ç”¨æ–¹æ³•

### Web ç•Œé¢

å¯åŠ¨ Web æœåŠ¡å™¨ï¼š

```bash
cd web_interface
python app.py
```

åœ¨ `http://localhost:5000` è®¿é—®ç•Œé¢

#### åŠŸèƒ½ï¼š
- **åµŒå…¥æ¶ˆæ¯**ï¼šä¸Šä¼ å›¾åƒå¹¶è¾“å…¥è¦éšè—çš„ç§˜å¯†æ¶ˆæ¯
- **æå–æ¶ˆæ¯**ï¼šä¸Šä¼ éšå†™å›¾åƒä»¥æå–éšè—æ¶ˆæ¯
- **æ‰¹é‡å¤„ç†**ï¼šä¸€æ¬¡å¤„ç†å¤šå¼ å›¾åƒ

### å‘½ä»¤è¡Œ

```bash
# å°†æ¶ˆæ¯ç¼–ç åˆ°å›¾åƒä¸­
imgsteggan encode input.png output.png "Your secret message"

# ä»å›¾åƒä¸­è§£ç æ¶ˆæ¯
imgsteggan decode output.png

# è®­ç»ƒæ–°æ¨¡å‹
python train.py --data_dir ./data --output_dir ./output
```

### Python API

```python
from steganogan.qwen_integration import QwenSteganoGAN

# åŠ è½½æ¨¡å‹
model = QwenSteganoGAN.load('output_qwen/qwen_steganogan.steg')

# ç¼–ç æ¶ˆæ¯
model.encode('cover_image.png', 'output_image.png', 'Secret message')

# è§£ç æ¶ˆæ¯
message = model.decode('output_image.png')
print(message)  # 'Secret message'
```

## æ¨¡å‹è®­ç»ƒ

è®­ç»ƒæ‚¨è‡ªå·±çš„æ¨¡å‹ï¼š

```bash
python train.py \
    --data_dir /path/to/training/images \
    --output_dir output_qwen \
    --epochs 5 \
    --batch_size 4 \
    --image_size 128
```

### è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | æè¿° |
|-----------|---------|-------------|
| `--data_dir` | å¿…å¡« | è®­ç»ƒå›¾åƒè·¯å¾„ |
| `--output_dir` | `output_qwen` | æ¨¡å‹è¾“å‡ºç›®å½• |
| `--epochs` | 5 | è®­ç»ƒè½®æ•° |
| `--batch_size` | 4 | è®­ç»ƒæ‰¹æ¬¡å¤§å° |
| `--image_size` | 128 | è®­ç»ƒå›¾åƒå°ºå¯¸ |
| `--lr` | 2e-4 | å­¦ä¹ ç‡ |
| `--cuda` | è‡ªåŠ¨ | å¦‚æœå¯ç”¨åˆ™ä½¿ç”¨ CUDA |

## æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|--------|-------|
| è§£ç æˆåŠŸç‡ | 100% |
| PSNR | â‰¥34 dB |
| SSIM | â‰¥0.99 |
| è§£ç æ—¶é—´ | â‰¤10 ç§’ï¼ˆå…¸å‹å›¾åƒï¼‰ |
| ç»´åº¦åŒ¹é… | 100% |

## æŠ€æœ¯ç»†èŠ‚

### æ¶æ„

- **ç¼–ç å™¨**ï¼šå…·æœ‰åŸºäºæ³¨æ„åŠ›ä½ç½®é€‰æ‹©çš„å¯†é›†ç¼–ç å™¨
- **è§£ç å™¨**ï¼šå…·æœ‰å¤šå°ºåº¦ç‰¹å¾æå–çš„æ®‹å·®è§£ç å™¨
- **åˆ¤åˆ«å™¨**ï¼šç”¨äºå¯¹æŠ—è®­ç»ƒçš„åŸºç¡€åˆ¤åˆ«å™¨
- **æ¶ˆæ¯å¤„ç†å™¨**ï¼šReed-Solomon çº é”™ç¼–ç 

### æ”¯æŒçš„æ ¼å¼

- **è¾“å…¥**ï¼šPNGã€JPGã€JPEGã€BMP
- **è¾“å‡º**ï¼šPNGï¼ˆæ¨èç”¨äºæ— æŸæå–ï¼‰

### å®¹é‡

æ¶ˆæ¯å®¹é‡å–å†³äºå›¾åƒå°ºå¯¸ï¼š

- å®¹é‡ï¼ˆå­—èŠ‚ï¼‰â‰ˆ å®½ Ã— é«˜ Ã— 3 / 8
- æœ€å°æ¨èå›¾åƒå°ºå¯¸ï¼š256Ã—256 åƒç´ 

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è‡´è°¢

æœ¬é¡¹ç›®åŸºäº MIT Data To AI Lab çš„åŸå§‹ SteganoGAN é¡¹ç›®æ„å»ºã€‚æˆ‘ä»¬å‘åŸä½œè€…çš„åŸºç¡€å·¥ä½œè¡¨ç¤ºæ„Ÿè°¢ã€‚

### åŸå§‹é¡¹ç›®

**SteganoGAN: High Capacity Image Steganography with GANs**

- Authors: Kevin Alex Zhang, Alfredo Cuesta-Infante, Kalyan Veeramachaneni
- Institution: MIT EECS
- Year: 2019
- Paper: [arXiv:1901.03892](https://arxiv.org/abs/1901.03892)

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·åŒæ—¶å¼•ç”¨åŸå§‹ SteganoGAN è®ºæ–‡å’Œæœ¬é¡¹ç›®ï¼š

### åŸå§‹ SteganoGAN è®ºæ–‡

```bibtex
@article{zhang2019steganogan,
  title={SteganoGAN: High Capacity Image Steganography with GANs},
  author={Zhang, Kevin Alex and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
  journal={arXiv preprint arXiv:1901.03892},
  year={2019},
  url={https://arxiv.org/abs/1901.03892}
}
```

**æ–‡æœ¬å¼•ç”¨ï¼š**
> Zhang, Kevin Alex and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan. SteganoGAN: High Capacity Image Steganography with GANs. MIT EECS, January 2019.

---

<!-- ENGLISH VERSION -->
<a name="english-documentation"></a>
# English Documentation

<div align="right">

**[ä¸­æ–‡ç‰ˆæœ¬](#-ä¸­æ–‡æ–‡æ¡£)**

</div>

## ImgStegGAN: GAN-Driven Image Steganography with Qwen Enhancement

A high-performance image steganography system that combines Generative Adversarial Networks (GAN) with Qwen language model enhancement for secure and efficient hidden message embedding and extraction.

## Features

- **GAN-Based Steganography**: Utilizes deep learning GAN architecture for robust message hiding
- **Qwen Enhancement**: Integrated Qwen language model for semantic understanding and improved encoding
- **High Capacity**: Supports embedding large messages while maintaining image quality
- **Lossless Extraction**: 100% accurate message extraction with error correction
- **Dimension Preservation**: Output images maintain exact original dimensions
- **Web Interface**: Modern, professional web UI for easy operation
- **Batch Processing**: Support for processing multiple images simultaneously
- **GPU Acceleration**: CUDA support for faster processing

## Project Structure

```
ImgStegGAN/
â”œâ”€â”€ steganogan/                 # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                  # Command line interface
â”‚   â”œâ”€â”€ models.py               # GAN models
â”‚   â”œâ”€â”€ encoders.py             # Encoder architectures
â”‚   â”œâ”€â”€ decoders.py             # Decoder architectures
â”‚   â”œâ”€â”€ critics.py              # Discriminator networks
â”‚   â”œâ”€â”€ qwen_integration.py     # Qwen model integration
â”‚   â”œâ”€â”€ trainer.py              # Training utilities
â”‚   â”œâ”€â”€ data_loader.py          # Data loading utilities
â”‚   â”œâ”€â”€ utils.py                # Helper functions
â”‚   â”œâ”€â”€ compat.py               # PyTorch compatibility
â”‚   â””â”€â”€ config.py               # Configuration
â”œâ”€â”€ web_interface/              # Web application
â”‚   â”œâ”€â”€ app.py                  # Flask application
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/style.css       # Styles
â”‚   â”‚   â””â”€â”€ js/app.js           # Frontend logic
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html          # Main template
â”‚   â””â”€â”€ uploads/                # Upload directory
â”œâ”€â”€ output_qwen/                # Model outputs
â”‚   â””â”€â”€ qwen_steganogan.steg    # Pre-trained model
â”œâ”€â”€ train.py                    # Training script
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Documentation
```

## Installation

### Prerequisites

- Python 3.8 or higher
- PyTorch 2.0 or higher
- CUDA (optional, for GPU acceleration)

### Install from Source

```bash
# Clone the repository
git clone https://github.com/yourusername/ImgStegGAN.git
cd ImgStegGAN

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .
```

### Dependencies

```
torch>=2.0.0
torchvision>=0.15.0
Pillow>=9.0.0
numpy>=1.21.0
reedsolo>=1.0.0
tqdm>=4.64.0
flask>=2.0.0
flask-cors>=3.0.0
transformers>=4.30.0
```

## Qwen3 Model Configuration

This project uses Qwen3-0.6B for enhanced steganography.Please follow the steps below to configure the model.

### Step 1: Download Qwen3-0.6B Model

Download from one of the official sources:

| Source | URL |
|--------|-----|
| Hugging Face | https://huggingface.co/Qwen/Qwen3-0.6B |
| ModelScope | https://modelscope.cn/models/Qwen/Qwen3-0.6B |

**Recommended version**: Qwen3-0.6B (approximately 1.2GB)

### Step 2: Create Model Directory

```bash
# Create the Qwen directory in project root
mkdir -p Qwen/Qwen3-0.6B
```

### Step 3: Place Model Files

Download and place the following files in `Qwen/Qwen3-0.6B/`:

```
Qwen/
â””â”€â”€ Qwen3-0.6B/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ generation_config.json
    â”œâ”€â”€ merges.txt
    â”œâ”€â”€ model.safetensors      # or pytorch_model.bin
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ vocab.json
```

### Step 4: Verify Configuration

Run the verification script:

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_path = "./Qwen/Qwen3-0.6B"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)

print("Qwen3 model loaded successfully!")
```

### Alternative: Use Hugging Face Auto-download

If you have a stable internet connection, the model can be auto-downloaded on first run:

```python
# Set environment variable (optional)
import os
os.environ['QWEN_MODEL_NAME'] = 'Qwen/Qwen3-0.6B'

# Or in code
from steganogan.qwen_integration import QwenSteganoGAN
model = QwenSteganoGAN(use_local_model=False)  # Will download from HuggingFace
```

For detailed configuration, see [MODEL_SETUP.md](MODEL_SETUP.md).

## Training Datasets

The following datasets were used for training the steganography model.

| Dataset | Description | Size | Source |
|---------|-------------|------|--------|
| Flickr2K | High-quality images for training | ~2GB | [HuggingFace](https://huggingface.co/datasets/laion/Flickr2K) |
| DIV2K | Diverse high-resolution images | ~3.5GB | [Data](https://data.vision.ee.ethz.ch/cvl/DIV2K/) |
| COCO-2017 | Common objects in context | ~18GB | [COCO](https://cocodataset.org/) |

### Training Data Preparation

1. Download the datasets from the sources above
2. Place images in `research/data/[dataset_name]/images/`
3. Run training: `python train.py --data_root ./research/data`

## Usage

### Web Interface

Start the web server:

```bash
cd web_interface
python app.py
```

Access the interface at `http://localhost:5000`

#### Features:
- **Embed Message**: Upload an image and enter the secret message to hide
- **Extract Message**: Upload a steganographic image to extract hidden message
- **Batch Processing**: Process multiple images at once

### Command Line

```bash
# Encode a message into an image
imgsteggan encode input.png output.png "Your secret message"

# Decode a message from an image
imgsteggan decode output.png

# Train a new model
python train.py --data_dir ./data --output_dir ./output
```

### Python API

```python
from steganogan.qwen_integration import QwenSteganoGAN

# Load the model
model = QwenSteganoGAN.load('output_qwen/qwen_steganogan.steg')

# Encode a message
model.encode('cover_image.png', 'output_image.png', 'Secret message')

# Decode a message
message = model.decode('output_image.png')
print(message)  # 'Secret message'
```

## Model Training

Train your own model:

```bash
python train.py \
    --data_dir /path/to/training/images \
    --output_dir output_qwen \
    --epochs 5 \
    --batch_size 4 \
    --image_size 128
```

### Training Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--data_dir` | Required | Path to training images |
| `--output_dir` | `output_qwen` | Output directory for model |
| `--epochs` | 5 | Number of training epochs |
| `--batch_size` | 4 | Batch size for training |
| `--image_size` | 128 | Image size for training |
| `--lr` | 2e-4 | Learning rate |
| `--cuda` | Auto | Use CUDA if available |

## Performance

| Metric | Value |
|--------|-------|
| Decode Success Rate | 100% |
| PSNR | â‰¥34 dB |
| SSIM | â‰¥0.99 |
| Decode Time | â‰¤10s (typical image) |
| Dimension Match | 100% |

## Technical Details

### Architecture

- **Encoder**: Dense encoder with attention-based position selection
- **Decoder**: Residual decoder with multi-scale feature extraction
- **Critic**: Basic critic for adversarial training
- **Message Processor**: Reed-Solomon error correction encoding

### Supported Formats

- **Input**: PNG, JPG, JPEG, BMP
- **Output**: PNG (recommended for lossless extraction)

### Capacity

The message capacity depends on image dimensions:
- Capacity (bytes) â‰ˆ Width Ã— Height Ã— 3 / 8
- Minimum recommended image size: 256Ã—256 pixels

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

This project is built upon the original SteganoGAN project by MIT Data To AI Lab. We extend our gratitude to the original authors for their foundational work.

### Original Project

**SteganoGAN: High Capacity Image Steganography with GANs**

- Authors: Kevin Alex Zhang, Alfredo Cuesta-Infante, Kalyan Veeramachaneni
- Institution: MIT EECS
- Year: 2019
- Paper: [arXiv:1901.03892](https://arxiv.org/abs/1901.03892)

## Citation

If you use this project in your research, please cite both the original SteganoGAN paper and this project:

### Original SteganoGAN Paper

```bibtex
@article{zhang2019steganogan,
  title={SteganoGAN: High Capacity Image Steganography with GANs},
  author={Zhang, Kevin Alex and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
  journal={arXiv preprint arXiv:1901.03892},
  year={2019},
  url={https://arxiv.org/abs/1901.03892}
}
```

**Text Citation:**
> Zhang, Kevin Alex and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan. SteganoGAN: High Capacity Image Steganography with GANs. MIT EECS, January 2019.